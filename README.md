# YOLOv8-MediaPipe-Fusion
YOLOv8-MediaPipe Fusion for Real-time Pose Estimation and Motion Replication in Unity3D

Abstract: 
This study presents an innovative approach for real-time human pose detection and motion replication within Unity3D environments by integrating YOLOv8, a state-of-the-art object detection model, with MediaPipe, a pre-trained pose estimation model. A custom dataset combining samples from the COCO 2017 and OChuman datasets is utilized to fine-tune the YOLOv8 model, enhancing its accuracy in human pose detection. Comparative analysis reveals that the fine-tuned YOLOv8 model achieves promising results in terms of accuracy, speed, and practical applicability, outperforming the pretrained MediaPipe model in certain aspects. Integrating these pose detection models into Unity3D enables seamless replication of human motion, paving the way for more efficient and realistic 3D character animation systems. Experimental results demonstrate the effectiveness of our proposed method, showcasing its potential for applications in virtual reality, gaming, and motion capture. This research contributes to advancing the fields of computer vision and virtual character animation by offering an accessible and cost-effective solution for animating 3D characters using real-world movements.

Tools:
Test h/w setup: AMD Ryzen 3600 processor, Nvidia GTX 1660 Super GPU, Maximum thermal envelope (TDP): 65W.
Library and Software Versions:
      Python 3.12 and cv2 3.8 
      Libraries: Ultralytics YOLOv8, CvZone,       PyTorch, TensorFlow.
Development Tools: PyCharm (Python), Unity 3D 2024, Microsoft Visual Studio Community (C#).
